#!/usr/bin/env python3
"""
Modified Crypto AI Trader
Uses existing data files for live trading instead of always downloading fresh data
"""

import os
import sys
import json
import time
import yaml
import joblib
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from datetime import datetime, timezone, timedelta
from binance.spot import Spot as SpotClient
from binance.error import ClientError
from sklearn.preprocessing import StandardScaler

# Import the original functions
from crypto_ai_trader import (
    load_env_file, make_client, build_tf_features, 
    MLP, place_market_buy, place_market_sell
)

def load_existing_data(config: dict):
    """Load existing data from files instead of downloading"""
    
    print("üìÅ Loading existing data from files...")
    
    tf_data = {}
    for tf in config["timeframes"]:
        filename = f"data/ETHUSDC_{tf}.csv"
        if os.path.exists(filename):
            df = pd.read_csv(filename)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.set_index('timestamp')
            
            # Convert to numeric
            for col in ['open', 'high', 'low', 'close', 'volume']:
                df[col] = pd.to_numeric(df[col])
            
            tf_data[tf] = df
            print(f"‚úÖ {tf}: {len(df)} bars, latest: {df.index[-1]}")
        else:
            print(f"‚ùå File not found: {filename}")
            return None
    
    return tf_data

def latest_features_and_signal_modified(client: SpotClient, config: dict, scaler: StandardScaler, model: nn.Module):
    """
    Modified version that uses existing data files instead of downloading fresh data
    """
    symbol = config["symbol"]
    base_tf = config["base_timeframe"]
    
    # Load existing data instead of downloading
    tf_data = load_existing_data(config)
    if tf_data is None:
        return None, None, None
    
    # Check if we have recent enough data
    base_candles = tf_data[base_tf]
    latest_time = base_candles.index[-1]
    current_time = datetime.now(timezone.utc)
    
    # Ensure both are timezone-aware
    if latest_time.tzinfo is None:
        latest_time = latest_time.replace(tzinfo=timezone.utc)
    
    time_diff = current_time - latest_time
    
    print(f"üìÖ Latest data: {latest_time}")
    print(f"üìÖ Current time: {current_time}")
    print(f"üìÖ Time difference: {time_diff}")
    
    # If data is too old (more than 2 hours), return None
    if time_diff.total_seconds() > 7200:  # 2 hours
        print(f"‚ö†Ô∏è  Data is too old: {time_diff.total_seconds()/3600:.1f} hours")
        return None, None, None
    
    # Build features from existing data
    feats = {tf: build_tf_features(df, prefix=tf) for tf, df in tf_data.items()}
    others = {tf: feat for tf, feat in feats.items() if tf != base_tf}
    
    # Fix the merge_asof issue by ensuring proper column names
    base_features = feats[base_tf].copy()
    base_features = base_features.sort_index().reset_index()
    base_features = base_features.rename(columns={base_features.index.name or "timestamp": "ts"})
    
    # Merge features manually to avoid the column name issue
    merged = base_features.copy()
    for name, feat in others.items():
        f = feat.sort_index().reset_index()
        f = f.rename(columns={f.index.name or "timestamp": "ts"})
        merged = pd.merge_asof(merged.sort_values("ts"), f.sort_values("ts"), on="ts", direction="backward")
    
    merged = merged.set_index("ts").sort_index()
    X_now = merged.dropna()
    
    if X_now.empty:
        print("‚ö†Ô∏è  No features after merging")
        return None, None, None
    
    print(f"‚úÖ Features built: {X_now.shape}")
    
    # Get prediction
    cols = X_now.columns.tolist()
    X_sc = scaler.transform(X_now.values)
    device = next(model.parameters()).device
    
    with torch.no_grad():
        proba = model(torch.tensor(X_sc, dtype=torch.float32, device=device)).cpu().numpy().ravel()
    
    proba_series = pd.Series(proba, index=X_now.index, name="proba")
    last_ts = proba_series.index[-1]
    last_proba = float(proba_series.iloc[-1])
    last_price = float(base_candles.loc[last_ts, "close"])
    
    return last_ts, last_proba, last_price

def run_live_loop_modified(config: dict):
    """Modified live loop that uses existing data"""
    
    env = load_env_file()
    api_key = env.get("BINANCE_API_KEY", os.environ.get("BINANCE_API_KEY", ""))
    api_secret = env.get("BINANCE_API_SECRET", os.environ.get("BINANCE_API_SECRET", ""))
    use_testnet = env.get("USE_TESTNET", str(config.get("use_testnet", True))).lower() == "true"
    dry_run = env.get("DRY_RUN", str(config["live"]["dry_run"])).lower() == "true"
    trade_quote_size = float(env.get("TRADE_QUOTE_SIZE", config["live"]["trade_quote_size"]))

    client = make_client(api_key, api_secret, use_testnet=use_testnet)

    # Load artifacts
    artifacts_dir = config["storage"]["artifacts_dir"]
    model_path = os.path.join(artifacts_dir, "model.pt")
    scaler_path = os.path.join(artifacts_dir, "scaler.pkl")

    if not (os.path.exists(model_path) and os.path.exists(scaler_path)):
        print("[ERROR] Train the model first to create artifacts.")
        return

    scaler = joblib.load(scaler_path)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Re-create model with correct input size
    sample_cols = joblib.load(os.path.join(artifacts_dir, "feature_columns.json"))
    model = MLP(in_features=len(sample_cols))
    model.load_state_dict(torch.load(model_path, map_location=device))
    model = model.to(device).eval()

    print("üöÄ Starting MODIFIED live loop (using existing data)")
    print("üìÅ Data source: Existing files in data/ directory")
    print("‚è∞ Press Ctrl+C to stop")
    
    position_file = os.path.join(artifacts_dir, "position_state.json")
    
    # Simple position state
    if os.path.exists(position_file):
        with open(position_file,"r") as f:
            state = json.load(f)
    else:
        state = {"has_position": False, "base_qty": 0.0}

    threshold = config["backtest"]["threshold"]

    try:
        while True:
            ts, proba, price = latest_features_and_signal_modified(client, config, scaler, model)
            if ts is None:
                print("‚è≥ Waiting for enough data...")
                time.sleep(config["live"]["poll_seconds"])
                continue
                
            print(f"üéØ [{ts}] proba_up={proba:.3f} price={price:.2f}")
            
            if (proba is not None) and (proba > threshold) and not state["has_position"]:
                # Enter long
                if dry_run:
                    print(f"üü¢ DRY_RUN: would BUY ~{trade_quote_size} USDC of {config['symbol']}")
                    state["has_position"] = True
                    state["base_qty"] = (trade_quote_size / price) * 0.999  # fee slippage estimate
                else:
                    try:
                        order = place_market_buy(client, config["symbol"], trade_quote_size)
                        fills_qty = sum(float(f["qty"]) for f in order.get("fills", [])) if "fills" in order else 0.0
                        state["has_position"] = True
                        state["base_qty"] = fills_qty if fills_qty>0 else (trade_quote_size/price)
                        print("üü¢ BUY order executed:", order)
                    except ClientError as e:
                        print("‚ùå BUY error:", e)
                        
            elif state["has_position"]:
                # Naive exit: after one base bar, just sell on next loop iteration
                if dry_run:
                    print(f"üî¥ DRY_RUN: would SELL {state['base_qty']:.6f} {config['symbol'][:-4]}")
                    state["has_position"] = False
                    state["base_qty"] = 0.0
                else:
                    try:
                        order = place_market_sell(client, config["symbol"], state["base_qty"])
                        state["has_position"] = False
                        state["base_qty"] = 0.0
                        print("üî¥ SELL order executed:", order)
                    except ClientError as e:
                        print("‚ùå SELL error:", e)

            # Save position state
            with open(position_file,"w") as f:
                json.dump(state, f)

            time.sleep(config["live"]["poll_seconds"])
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Stopped.")

if __name__ == "__main__":
    print("üöÄ Modified Crypto AI Trader - Live Trading Mode")
    print("=" * 60)
    
    # Load config
    config_path = "config_live_trading.yaml"
    if os.path.exists(config_path):
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        print(f"‚úÖ Loaded config: {config_path}")
    else:
        print(f"‚ùå Config not found: {config_path}")
        sys.exit(1)
    
    # Start modified live loop
    run_live_loop_modified(config)
